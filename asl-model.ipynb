{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":29550,"sourceType":"datasetVersion","datasetId":23079}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# ===== Fix for np.bool / np.object error (Keep for environment compatibility) =====\nimport numpy as np\nif not hasattr(np, 'bool'):\n    np.bool = bool\nif not hasattr(np, 'object'):\n    np.object = object\n# =================================================================================\n\nimport os\nimport cv2\nimport mediapipe as mp\nimport numpy as np\nimport tensorflow as tf\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelBinarizer\n\n# Step 1: Install required libraries\n!pip install mediapipe\n\n# --- Data Loading and Feature Extraction ---\ndata_dir = \"/kaggle/input/asl-alphabet/asl_alphabet_train/asl_alphabet_train/\"\n\n# Dynamically get class names from folder names\nclasses = sorted([d for d in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, d))])\n\nmp_hands = mp.solutions.hands\nhands = mp_hands.Hands(static_image_mode=True, max_num_hands=1, min_detection_confidence=0.5)\n\nX = []  # Features (landmarks)\ny = []  # Labels (class indices)\n\nprint(\"Starting feature extraction...\")\n\nfor i, class_name in enumerate(classes):\n    class_dir = os.path.join(data_dir, class_name)\n    print(f\"Processing class: {class_name} ({i+1}/{len(classes)})\")\n    \n    image_files = os.listdir(class_dir)[:500]  # Use a subset of 500 images\n    \n    for image_file in image_files:\n        image_path = os.path.join(class_dir, image_file)\n        image = cv2.imread(image_path)\n        if image is None:\n            continue\n        \n        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        results = hands.process(image_rgb)\n        \n        if results.multi_hand_landmarks:\n            for hand_landmarks in results.multi_hand_landmarks:\n                landmarks = []\n                for landmark in hand_landmarks.landmark:\n                    landmarks.extend([landmark.x, landmark.y, landmark.z])\n                X.append(landmarks)\n                y.append(i)\n\nX = np.array(X)\ny = np.array(y)\n\nprint(\"Feature extraction completed.\")\nprint(f\"Total samples extracted: {len(X)}\")\n\n# --- Prepare Data for Training ---\nlb = LabelBinarizer()\ny_one_hot = lb.fit_transform(y)\nnum_classes = y_one_hot.shape[1]\nX_train, X_test, y_train, y_test = train_test_split(X, y_one_hot, test_size=0.2, random_state=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T02:12:11.925913Z","iopub.execute_input":"2025-09-25T02:12:11.926242Z","iopub.status.idle":"2025-09-25T02:18:26.667481Z","shell.execute_reply.started":"2025-09-25T02:12:11.926208Z","shell.execute_reply":"2025-09-25T02:18:26.666681Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_1620/1933065749.py:3: FutureWarning: In the future `np.bool` will be defined as the corresponding NumPy scalar.\n  if not hasattr(np, 'bool'):\n/tmp/ipykernel_1620/1933065749.py:5: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n  if not hasattr(np, 'object'):\n2025-09-25 02:12:12.351689: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1758766332.374034    1620 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1758766332.380902    1620 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: mediapipe in /usr/local/lib/python3.11/dist-packages (0.10.21)\nRequirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from mediapipe) (1.4.0)\nRequirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (25.3.0)\nRequirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (25.2.10)\nRequirement already satisfied: jax in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.5.2)\nRequirement already satisfied: jaxlib in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.5.1)\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from mediapipe) (3.7.2)\nRequirement already satisfied: numpy<2 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (1.26.4)\nRequirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.11/dist-packages (from mediapipe) (4.11.0.86)\nRequirement already satisfied: protobuf<5,>=4.25.3 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (4.25.8)\nRequirement already satisfied: sounddevice>=0.4.4 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.5.2)\nRequirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.2.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<2->mediapipe) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<2->mediapipe) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<2->mediapipe) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<2->mediapipe) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<2->mediapipe) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<2->mediapipe) (2.4.1)\nRequirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.11/dist-packages (from sounddevice>=0.4.4->mediapipe) (1.17.1)\nRequirement already satisfied: ml_dtypes>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from jax->mediapipe) (0.4.1)\nRequirement already satisfied: opt_einsum in /usr/local/lib/python3.11/dist-packages (from jax->mediapipe) (3.4.0)\nRequirement already satisfied: scipy>=1.11.1 in /usr/local/lib/python3.11/dist-packages (from jax->mediapipe) (1.15.3)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (1.3.2)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (4.58.4)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (1.4.8)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (25.0)\nRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (11.2.1)\nRequirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (3.0.9)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (2.9.0.post0)\nRequirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.22)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.17.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2->mediapipe) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2->mediapipe) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<2->mediapipe) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<2->mediapipe) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<2->mediapipe) (2024.2.0)\nStarting feature extraction...\nProcessing class: A (1/29)\n","output_type":"stream"},{"name":"stderr","text":"INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nW0000 00:00:1758766338.611665    1681 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\nW0000 00:00:1758766338.646243    1681 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\nW0000 00:00:1758766338.655734    1679 landmark_projection_calculator.cc:186] Using NORM_RECT without IMAGE_DIMENSIONS is only supported for the square ROI. Provide IMAGE_DIMENSIONS or use PROJECTION_MATRIX.\n","output_type":"stream"},{"name":"stdout","text":"Processing class: B (2/29)\nProcessing class: C (3/29)\nProcessing class: D (4/29)\nProcessing class: E (5/29)\nProcessing class: F (6/29)\nProcessing class: G (7/29)\nProcessing class: H (8/29)\nProcessing class: I (9/29)\nProcessing class: J (10/29)\nProcessing class: K (11/29)\nProcessing class: L (12/29)\nProcessing class: M (13/29)\nProcessing class: N (14/29)\nProcessing class: O (15/29)\nProcessing class: P (16/29)\nProcessing class: Q (17/29)\nProcessing class: R (18/29)\nProcessing class: S (19/29)\nProcessing class: T (20/29)\nProcessing class: U (21/29)\nProcessing class: V (22/29)\nProcessing class: W (23/29)\nProcessing class: X (24/29)\nProcessing class: Y (25/29)\nProcessing class: Z (26/29)\nProcessing class: del (27/29)\nProcessing class: nothing (28/29)\nProcessing class: space (29/29)\nFeature extraction completed.\nTotal samples extracted: 10648\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout\n\n# --- Model Building and Training ---\nprint(\"\\nBuilding and training the TensorFlow model...\")\nprint(f\"Shape of training data: {X_train.shape}\")\nprint(f\"Number of classes detected: {num_classes}\")\n\nmodel = Sequential([\n    Dense(256, activation='relu', input_shape=(63,)),\n    Dropout(0.3),\n    Dense(128, activation='relu'),\n    Dropout(0.3),\n    Dense(num_classes, activation='softmax')\n])\n\nmodel.compile(optimizer='adam',\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])\n\nmodel.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.1)\n\nloss, accuracy = model.evaluate(X_test, y_test, verbose=0)\nprint(f\"\\nModel evaluation on test data - Loss: {loss:.4f}, Accuracy: {accuracy:.4f}\")\n\n# Simpan model dalam format native Keras 3 yang direkomendasikan\nkeras_filename = \"asl_landmark_model.keras\"\nmodel.save(keras_filename)\nprint(f\"TensorFlow model saved in native Keras 3 format to '{keras_filename}'\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T02:25:03.913761Z","iopub.execute_input":"2025-09-25T02:25:03.914474Z","iopub.status.idle":"2025-09-25T02:25:38.801158Z","shell.execute_reply.started":"2025-09-25T02:25:03.914440Z","shell.execute_reply":"2025-09-25T02:25:38.800459Z"}},"outputs":[{"name":"stdout","text":"\nBuilding and training the TensorFlow model...\nShape of training data: (8518, 63)\nNumber of classes detected: 28\nEpoch 1/50\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m240/240\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.1162 - loss: 3.1263 - val_accuracy: 0.5634 - val_loss: 1.7818\nEpoch 2/50\n\u001b[1m240/240\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4881 - loss: 1.6693 - val_accuracy: 0.7852 - val_loss: 0.8991\nEpoch 3/50\n\u001b[1m240/240\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7023 - loss: 0.9615 - val_accuracy: 0.8638 - val_loss: 0.5785\nEpoch 4/50\n\u001b[1m240/240\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7853 - loss: 0.6999 - val_accuracy: 0.8697 - val_loss: 0.4738\nEpoch 5/50\n\u001b[1m240/240\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8187 - loss: 0.5838 - val_accuracy: 0.9120 - val_loss: 0.3796\nEpoch 6/50\n\u001b[1m240/240\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8480 - loss: 0.5095 - val_accuracy: 0.9190 - val_loss: 0.3341\nEpoch 7/50\n\u001b[1m240/240\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8637 - loss: 0.4391 - val_accuracy: 0.8932 - val_loss: 0.3408\nEpoch 8/50\n\u001b[1m240/240\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8824 - loss: 0.3734 - val_accuracy: 0.9425 - val_loss: 0.2745\nEpoch 9/50\n\u001b[1m240/240\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9051 - loss: 0.3330 - val_accuracy: 0.9519 - val_loss: 0.2595\nEpoch 10/50\n\u001b[1m240/240\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8989 - loss: 0.3335 - val_accuracy: 0.9472 - val_loss: 0.2295\nEpoch 11/50\n\u001b[1m240/240\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9115 - loss: 0.2810 - val_accuracy: 0.9554 - val_loss: 0.2225\nEpoch 12/50\n\u001b[1m240/240\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9179 - loss: 0.2605 - val_accuracy: 0.9343 - val_loss: 0.2236\nEpoch 13/50\n\u001b[1m240/240\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9166 - loss: 0.2692 - val_accuracy: 0.9507 - val_loss: 0.2043\nEpoch 14/50\n\u001b[1m240/240\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9245 - loss: 0.2442 - val_accuracy: 0.9484 - val_loss: 0.1958\nEpoch 15/50\n\u001b[1m240/240\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9229 - loss: 0.2574 - val_accuracy: 0.9566 - val_loss: 0.1876\nEpoch 16/50\n\u001b[1m240/240\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9331 - loss: 0.2382 - val_accuracy: 0.9425 - val_loss: 0.1880\nEpoch 17/50\n\u001b[1m240/240\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9318 - loss: 0.2236 - val_accuracy: 0.9531 - val_loss: 0.1799\nEpoch 18/50\n\u001b[1m240/240\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9385 - loss: 0.2031 - val_accuracy: 0.9554 - val_loss: 0.1777\nEpoch 19/50\n\u001b[1m240/240\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9464 - loss: 0.1839 - val_accuracy: 0.9589 - val_loss: 0.1561\nEpoch 20/50\n\u001b[1m240/240\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9437 - loss: 0.1919 - val_accuracy: 0.9566 - val_loss: 0.1584\nEpoch 21/50\n\u001b[1m240/240\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9412 - loss: 0.1864 - val_accuracy: 0.9542 - val_loss: 0.1578\nEpoch 22/50\n\u001b[1m240/240\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9411 - loss: 0.1925 - val_accuracy: 0.9648 - val_loss: 0.1581\nEpoch 23/50\n\u001b[1m240/240\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9432 - loss: 0.1730 - val_accuracy: 0.9507 - val_loss: 0.1701\nEpoch 24/50\n\u001b[1m240/240\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9310 - loss: 0.2011 - val_accuracy: 0.9648 - val_loss: 0.1398\nEpoch 25/50\n\u001b[1m240/240\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9489 - loss: 0.1735 - val_accuracy: 0.9636 - val_loss: 0.1464\nEpoch 26/50\n\u001b[1m240/240\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9499 - loss: 0.1714 - val_accuracy: 0.9577 - val_loss: 0.1544\nEpoch 27/50\n\u001b[1m240/240\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9446 - loss: 0.1713 - val_accuracy: 0.9648 - val_loss: 0.1485\nEpoch 28/50\n\u001b[1m240/240\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9431 - loss: 0.1705 - val_accuracy: 0.9319 - val_loss: 0.2126\nEpoch 29/50\n\u001b[1m240/240\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9358 - loss: 0.1811 - val_accuracy: 0.9648 - val_loss: 0.1357\nEpoch 30/50\n\u001b[1m240/240\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9451 - loss: 0.1654 - val_accuracy: 0.9636 - val_loss: 0.1361\nEpoch 31/50\n\u001b[1m240/240\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9493 - loss: 0.1507 - val_accuracy: 0.9577 - val_loss: 0.1533\nEpoch 32/50\n\u001b[1m240/240\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9452 - loss: 0.1557 - val_accuracy: 0.9636 - val_loss: 0.1459\nEpoch 33/50\n\u001b[1m240/240\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9499 - loss: 0.1522 - val_accuracy: 0.9648 - val_loss: 0.1340\nEpoch 34/50\n\u001b[1m240/240\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9521 - loss: 0.1414 - val_accuracy: 0.9636 - val_loss: 0.1375\nEpoch 35/50\n\u001b[1m240/240\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9493 - loss: 0.1417 - val_accuracy: 0.9589 - val_loss: 0.1474\nEpoch 36/50\n\u001b[1m240/240\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9466 - loss: 0.1651 - val_accuracy: 0.9683 - val_loss: 0.1355\nEpoch 37/50\n\u001b[1m240/240\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9531 - loss: 0.1408 - val_accuracy: 0.9648 - val_loss: 0.1381\nEpoch 38/50\n\u001b[1m240/240\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9536 - loss: 0.1401 - val_accuracy: 0.9671 - val_loss: 0.1469\nEpoch 39/50\n\u001b[1m240/240\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9455 - loss: 0.1511 - val_accuracy: 0.9660 - val_loss: 0.1353\nEpoch 40/50\n\u001b[1m240/240\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9522 - loss: 0.1352 - val_accuracy: 0.9777 - val_loss: 0.1259\nEpoch 41/50\n\u001b[1m240/240\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9537 - loss: 0.1425 - val_accuracy: 0.9695 - val_loss: 0.1252\nEpoch 42/50\n\u001b[1m240/240\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9614 - loss: 0.1163 - val_accuracy: 0.9718 - val_loss: 0.1206\nEpoch 43/50\n\u001b[1m240/240\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9598 - loss: 0.1316 - val_accuracy: 0.9800 - val_loss: 0.1155\nEpoch 44/50\n\u001b[1m240/240\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9593 - loss: 0.1290 - val_accuracy: 0.9754 - val_loss: 0.1176\nEpoch 45/50\n\u001b[1m240/240\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9605 - loss: 0.1141 - val_accuracy: 0.9730 - val_loss: 0.1191\nEpoch 46/50\n\u001b[1m240/240\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9585 - loss: 0.1308 - val_accuracy: 0.9671 - val_loss: 0.1224\nEpoch 47/50\n\u001b[1m240/240\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9595 - loss: 0.1178 - val_accuracy: 0.9730 - val_loss: 0.1262\nEpoch 48/50\n\u001b[1m240/240\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9630 - loss: 0.1115 - val_accuracy: 0.9777 - val_loss: 0.1180\nEpoch 49/50\n\u001b[1m240/240\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9558 - loss: 0.1348 - val_accuracy: 0.9742 - val_loss: 0.1092\nEpoch 50/50\n\u001b[1m240/240\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9585 - loss: 0.1249 - val_accuracy: 0.9683 - val_loss: 0.1142\n\nModel evaluation on test data - Loss: 0.1061, Accuracy: 0.9751\nTensorFlow model saved in native Keras 3 format to 'asl_landmark_model.keras'\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"import tf2onnx\nimport onnx\nimport tensorflow as tf\nfrom tensorflow.keras.models import Model, load_model\nfrom tensorflow.keras.layers import Input, Dense, Dropout\nimport os \nimport numpy as np\n\n# Pastikan library sudah terinstal\n!pip install tf2onnx onnx\n\n# --- ONNX Conversion ---\nprint(\"\\nConverting Model to ONNX...\")\n\nkeras_filename = \"asl_landmark_model.keras\" \nonnx_filename = \"asl_landmark_model.onnx\"\ninput_dim = 63 \n\ntry:\n    # 1. Muat model Keras\n    if not os.path.exists(keras_filename):\n        raise FileNotFoundError(f\"File model Keras tidak ditemukan: {keras_filename}. Pastikan Anda sudah melatih dan menyimpan modelnya.\")\n        \n    sequential_model = load_model(keras_filename)\n    \n    # ðŸ’¥ PERBAIKAN: Gunakan .units untuk mendapatkan jumlah output dari lapisan Dense terakhir.\n    # [:-1] mengambil lapisan Dense terakhir dari model Sequential\n    num_classes = sequential_model.layers[-1].units \n    \n    # 2. Buat ulang model sebagai Functional API Model\n    print(f\"Model memiliki {num_classes} kelas. Merekonstruksi sebagai Functional API Model...\")\n    \n    input_tensor = Input(shape=(input_dim,), name='input_features')\n    # Mereplikasi arsitektur asli\n    x = Dense(256, activation='relu', name='dense_1')(input_tensor)\n    x = Dropout(0.3)(x)\n    x = Dense(128, activation='relu', name='dense_2')(x)\n    x = Dropout(0.3)(x)\n    output_tensor = Dense(num_classes, activation='softmax', name='output_softmax')(x)\n    \n    functional_model = Model(inputs=input_tensor, outputs=output_tensor)\n\n    # 3. Transfer bobot dari model Sequential yang dilatih ke Functional Model\n    functional_model.set_weights(sequential_model.get_weights())\n    \n    # 4. Definisikan Input Signature\n    input_signature = [\n        tf.TensorSpec([None, input_dim], tf.float32, name='input_features')\n    ]\n    \n    # 5. Konversi menggunakan fungsi from_keras\n    onnx_model, _ = tf2onnx.convert.from_keras(\n        functional_model, \n        input_signature=input_signature,\n        output_path=onnx_filename,\n        opset=13,\n    )\n    \n    print(f\"Model successfully converted and saved as '{onnx_filename}'\")\n    \nexcept Exception as e:\n    print(f\"Conversion failed: {e}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T02:28:44.905309Z","iopub.execute_input":"2025-09-25T02:28:44.905935Z","iopub.status.idle":"2025-09-25T02:28:48.189910Z","shell.execute_reply.started":"2025-09-25T02:28:44.905900Z","shell.execute_reply":"2025-09-25T02:28:48.188981Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: tf2onnx in /usr/local/lib/python3.11/dist-packages (1.8.4)\nRequirement already satisfied: onnx in /usr/local/lib/python3.11/dist-packages (1.18.0)\nRequirement already satisfied: numpy>=1.14.1 in /usr/local/lib/python3.11/dist-packages (from tf2onnx) (1.26.4)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from tf2onnx) (2.32.4)\nRequirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from tf2onnx) (1.17.0)\nRequirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from tf2onnx) (25.2.10)\nRequirement already satisfied: protobuf>=4.25.1 in /usr/local/lib/python3.11/dist-packages (from onnx) (4.25.8)\nRequirement already satisfied: typing_extensions>=4.7.1 in /usr/local/lib/python3.11/dist-packages (from onnx) (4.14.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.14.1->tf2onnx) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.14.1->tf2onnx) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.14.1->tf2onnx) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.14.1->tf2onnx) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.14.1->tf2onnx) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.14.1->tf2onnx) (2.4.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->tf2onnx) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->tf2onnx) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->tf2onnx) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->tf2onnx) (2025.6.15)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.14.1->tf2onnx) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.14.1->tf2onnx) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.14.1->tf2onnx) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.14.1->tf2onnx) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.14.1->tf2onnx) (2024.2.0)\n\nConverting Model to ONNX...\nModel memiliki 28 kelas. Merekonstruksi sebagai Functional API Model...\nModel successfully converted and saved as 'asl_landmark_model.onnx'\n","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1758767328.107544    1620 devices.cc:67] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 2\nI0000 00:00:1758767328.107746    1620 single_machine.cc:361] Starting new session\nI0000 00:00:1758767328.109917    1620 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\nI0000 00:00:1758767328.110111    1620 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13942 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\nI0000 00:00:1758767328.136227    1620 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\nI0000 00:00:1758767328.136480    1620 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13942 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\nI0000 00:00:1758767328.140643    1620 devices.cc:67] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 2\nI0000 00:00:1758767328.140816    1620 single_machine.cc:361] Starting new session\nI0000 00:00:1758767328.142997    1620 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\nI0000 00:00:1758767328.143227    1620 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13942 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n","output_type":"stream"}],"execution_count":19}]}